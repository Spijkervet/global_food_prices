{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from bokeh.layouts import gridplot\n",
    "\n",
    "url_2 = \"https://raw.githubusercontent.com/lukes/ISO-3166-Countries-with-Regional-Codes/master/all/all.csv\"\n",
    "regional_file_name = \"regions.csv\"\n",
    "\n",
    "file_name = 'WFPVAM_FoodPrices_version4_Retail.csv'\n",
    "\n",
    "# Add region and datetime cols.\n",
    "df = pd.read_csv(file_name)\n",
    "df['date'] = pd.to_datetime(df.date, format='%Y-%m')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only_bread.plot(x='date', y='Diff')\n",
    "\n",
    "def datetime(x):\n",
    "    return np.array(x, dtype=np.datetime64)\n",
    "\n",
    "\n",
    "from bokeh.layouts import gridplot\n",
    "from bokeh.plotting import figure, show, output_file\n",
    "from bokeh.models import HoverTool\n",
    "\n",
    "\n",
    "# COLORS\n",
    "from bokeh.palettes import Dark2_5 as palette\n",
    "import itertools\n",
    "\n",
    "\n",
    "colors = itertools.cycle(palette)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "# Products per Country for each city.\n",
    "plots = []\n",
    "product_groups = df.groupby(['cm_name'])\n",
    "for prod_group, prod_row in product_groups:    \n",
    "    plot = figure(x_axis_type=\"datetime\", title=\"{} in {}\".format(prod_group, country), tools='hover')\n",
    "    \n",
    "    city_groups = prod_row.groupby(['mkt_name'])\n",
    "    for (group, row), color in zip(city_groups, colors):\n",
    "        plot.line(datetime(row['date']), row['Diff'], color=color, legend=group)\n",
    "    plot.legend.click_policy = \"hide\"\n",
    "    plot.legend.location = \"top_right\"\n",
    "    hover = plot.select(dict(type=HoverTool))\n",
    "    hover.tooltips = [\n",
    "        (\"Value\", \"$y\"),\n",
    "        ]\n",
    "    \n",
    "    plots.append(plot)\n",
    "\n",
    "# p2 = figure(x_axis_type=\"datetime\", title=\"Bread in Afghanistan\")\n",
    "# p2.line(datetime(df['date']), df['mp_price'], color='#A6CEE3', legend='Bread')\n",
    "\n",
    "# show(gridplot([plots]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "\n",
    "Are there any food prices that are show negative/positive correlation, and is this correlation present throughout the years, or perhaps only in certain period? Can you perhaps detect possible ingredients of a certain other food product?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each product in a graph for each country.\n",
    "\n",
    "country = 'Uganda'\n",
    "y_axis = 'Gradient'\n",
    "\n",
    "df_country = df.loc[df.adm0_name == country]\n",
    "plots = []\n",
    "country_groups = df_country.groupby(['mkt_name'])\n",
    "\n",
    "# allow for interactive hover tool\n",
    "# Import the ColumnDataSource\n",
    "from bokeh.models import ColumnDataSource\n",
    "\n",
    "\n",
    "\n",
    "for country_group, country_row in country_groups:\n",
    "    plot = figure(x_axis_type=\"datetime\", title=\"Products in {}\".format(country_group), tools='hover,pan,wheel_zoom,box_zoom,reset')\n",
    "    product_groups = country_row.groupby(['cm_name'])\n",
    "    for (group, row), color in zip(product_groups, colors):\n",
    "        # create CDS to enable dynamic hovering\n",
    "        row_cds = ColumnDataSource(row)\n",
    "        # set source to CDS\n",
    "        # OK to use Gradient for derivative?\n",
    "        plot.line('date', y_axis, color=color, legend=group, source=row_cds)\n",
    "    plot.legend.click_policy = \"hide\"\n",
    "    plot.legend.location = \"top_right\"\n",
    "    hover = plot.select(dict(type=HoverTool))\n",
    "    # set preffered info for hovertool to show\n",
    "    hover.tooltips = [\n",
    "        # need to fix daytime again now....\n",
    "        (\"date\", \"@date\"),\n",
    "        (\"product\", \"@cm_name\"),\n",
    "        (\"Gradient\", \"@Gradient\")\n",
    "        ]\n",
    "    \n",
    "    plots.append(plot)\n",
    "\n",
    "show(gridplot([plots]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "Do countries in similar regions, also show similar price differences? And if differences occur, can you find a potential explanation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each product in a graph for each country.\n",
    "\n",
    "\n",
    "region_df = pd.read_csv(regional_file_name)\n",
    "region_df.rename(columns={'name': 'adm0_name'}, inplace=True)\n",
    "new_regions = region_df.loc[:, ['adm0_name', 'sub-region']]\n",
    "\n",
    "df_regions = pd.merge(df, new_regions, on='adm0_name', how='left')\n",
    "df = df_regions.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_axis = 'Gradient'\n",
    "\n",
    "\n",
    "plots = []\n",
    "product_groups = df.groupby(['sub-region', 'cm_name', 'date'])[y_axis].mean().reset_index()\n",
    "group = product_groups.groupby('sub-region')\n",
    "\n",
    "for gr1, row1 in group:\n",
    "    plot = figure(x_axis_type=\"datetime\", title=\"Avg Products in {}\".format(gr1), tools='hover,pan,wheel_zoom,box_zoom,reset')\n",
    "    product_groups = row1.groupby(['cm_name'])\n",
    "    for (gr2, row2), color in zip(product_groups, colors):\n",
    "        row2_cds = ColumnDataSource(row2)\n",
    "        plot.line('date', y_axis, color=color, legend=gr2, source=row2_cds)\n",
    "    plot.legend.click_policy = \"hide\"\n",
    "    plot.legend.location = \"top_right\"\n",
    "    hover = plot.select(dict(type=HoverTool))\n",
    "    hover.tooltips = [\n",
    "        (\"Product\", \"@cm_name\"),\n",
    "        (\"Value\", \"@Gradient\"),\n",
    "        ]\n",
    "    \n",
    "    plots.append(plot)\n",
    "show(gridplot([plots]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "Can we see any correlations between other types of data, like: currency fluctuations, weather patterns, and/or refugee movements. Can we perhaps visualize refugee movements from the food price data? Do certain weather conditions influence market prices?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot set a Timestamp with a non-timestamp",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-bb5249c5e93c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mis_country\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdates\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mdate_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mis_country\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0mtotal_freq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mis_country\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdate_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'frequency'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;31m# update new dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other, axis)\u001b[0m\n\u001b[1;32m    877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mna_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m                 raise TypeError('Could not compare {typ} type with Series'\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mna_op\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    806\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m                     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m                     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.convert_scalar\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.convert_scalar\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot set a Timestamp with a non-timestamp"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# get datasets\n",
    "# https://data.world/unhcr/asylum-applications/workspace/file?filename=asylum_seekers_monthly_2016_12_08_152150.csv\n",
    "asylum_file = 'asylum_seekers_monthly_2016_12_08_152150.csv'\n",
    "df = pd.read_csv(asylum_file, low_memory=False)\n",
    "\n",
    "food_prices_file = 'WFPVAM_FoodPrices_version5_Retail.csv'\n",
    "df_food = pd.read_csv(food_prices_file)\n",
    "\n",
    "\n",
    "####### pre-processing #######################################################################\n",
    "\n",
    "df.columns = ['destination', 'origin', 'year', 'month', 'frequency']\n",
    "# remove abundant rows\n",
    "df.drop(df.index[:2], inplace=True)\n",
    "\n",
    "# map month names to corresponding number to allow for convertion to daytime\n",
    "MONTH_DICT = {'January': 1, 'February': 2, 'March': 3, 'April': 4, 'May': 5, 'June': 6, \n",
    "              'July': 7, 'August': 8, 'September': 9, 'October': 10, 'November': 11,\n",
    "              'December': 12}\n",
    "\n",
    "df['month'] = df['month'].map(MONTH_DICT)\n",
    "\n",
    "# month and year column to single daytime column 'date'\n",
    "df = df.assign(date=pd.to_datetime(df[['year', 'month']].assign(day=1)))\n",
    "# drop now abundant columns month and year\n",
    "df = df.drop('month', axis=1)\n",
    "df = df.drop('year', axis=1)\n",
    "\n",
    "# drop rows with undefined frequency\n",
    "df = df.drop(df[df.frequency == '*'].index)\n",
    "# also drop rows with unknown/various origins\n",
    "df = df.drop(df[df.origin == 'Various/unknown'].index)\n",
    "\n",
    "# NB: we could also drop the destination columns, since it only includes countries\n",
    "# outside of our original dataset. But maybe it will allow for some dynamic hovering later on...\n",
    "# so we'll keep it for now.\n",
    "\n",
    "# see if different names are used for identical counrtries in the two databases:\n",
    "# will end up with a list with countries that don't match; manually see if they should...\n",
    "countries_food = df_food['Iadm0_name'].unique()\n",
    "countries_refugee = df['origin'].unique()\n",
    "\n",
    "possible_mismatches_1 = [country for country in countries_food \n",
    "                       if country not in countries_refugee]\n",
    "\n",
    "possible_mismatches_2 = [country for country in countries_refugee\n",
    "                        if country not in countries_food]\n",
    "\n",
    "definite_mismatches = possible_mismatches_1 + possible_mismatches_2\n",
    "\n",
    "mismatches = definite_mismatches.sort()\n",
    "# print(mismatches)\n",
    "\n",
    "# {'country name in refugee file': 'corresponding country name in food dataset'}\n",
    "MISMATCH_DICT = {'Iran (Islamic Rep. of)': 'Iran  (Islamic Republic of)', 'Dem. Rep. of the Congo': 'Democratic Republic of the Congo',\n",
    "                 'Central African Rep.': 'Central African Republic'}\n",
    "\n",
    "# fix mis-matches\n",
    "for (original, new) in MISMATCH_DICT.items():\n",
    "    mask = df.origin == original\n",
    "    df.loc[mask, 'origin'] = new\n",
    "    \n",
    "# reset index\n",
    "df = df.reset_index(drop=True)\n",
    "df.head()\n",
    "###################################### pre-processing done ###################################\n",
    "\n",
    "\n",
    "# set food_prices dataset to daytime to allow merging with refugee dataset\n",
    "df_food['date'] = pd.to_datetime(df_food.date, format='%Y-%m')\n",
    "# merge datasets \n",
    "\n",
    "#new_df = pd.merge(df_food, df,  how='left', left_on=['Iadm0_name','date'], right_on = ['origin','date'])\n",
    "# drop now abundantan origin row (equals Iadm0_name)\n",
    "df[:50]\n",
    "\n",
    "# convert frequency values to integers to allow for summing\n",
    "df.frequency = df.frequency.astype(np.int64)\n",
    "\n",
    "is_country = df['destination'] == 'Albania'\n",
    "df[is_country]['date'].value_counts()\n",
    "\n",
    "date_mask = df[is_country]['date'] == '2006-11-01'\n",
    "total = (df[is_country][new_mask]['frequency']).sum()\n",
    "print(total)\n",
    "\n",
    "# make new dataframe\n",
    "#df_total = pd.DataFrame(columns=['origin','date','total'])\n",
    "\n",
    "# all_countries = df['origin'].unique()\n",
    "\n",
    "# for country in all_countries:\n",
    "#     # get all unique dates of current country\n",
    "#     is_country = df['origin'] == country\n",
    "#     dates = df[is_country]['date'].unique()\n",
    "#     for date in dates:\n",
    "#         date_mask = df[is_country]['date'] == date\n",
    "#         total_freq = df[is_country][date_mask]['frequency'].sum()\n",
    "#         # update new dataframe\n",
    "#         df_total.loc[-1] = [country, date, total_freq]\n",
    "            \n",
    "# df_total\n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
