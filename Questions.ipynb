{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Armenia', 'Democratic Republic of the Congo', 'Gambia',\n",
       "       'Kyrgyzstan', \"Lao People's Democratic Republic\", 'Peru',\n",
       "       'State of Palestine'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from bokeh.layouts import gridplot\n",
    "\n",
    "url_2 = \"https://raw.githubusercontent.com/lukes/ISO-3166-Countries-with-Regional-Codes/master/all/all.csv\"\n",
    "regional_file_name = \"regions.csv\"\n",
    "\n",
    "file_name = 'WFPVAM_FoodPrices_version4_Retail.csv'\n",
    "\n",
    "# Add region and datetime cols.\n",
    "df = pd.read_csv(file_name)\n",
    "df['date'] = pd.to_datetime(df.date, format='%Y-%m')\n",
    "\n",
    "\n",
    "country = df['adm0_name'] == \"Rwanda\"\n",
    "print(df['adm0_name'].unique())\n",
    "print(df[country]['cm_name'].unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only_bread.plot(x='date', y='Diff')\n",
    "\n",
    "def datetime(x):\n",
    "    return np.array(x, dtype=np.datetime64)\n",
    "\n",
    "\n",
    "from bokeh.layouts import gridplot\n",
    "from bokeh.plotting import figure, show, output_file\n",
    "from bokeh.models import HoverTool\n",
    "\n",
    "\n",
    "# COLORS\n",
    "from bokeh.palettes import Dark2_5 as palette\n",
    "import itertools\n",
    "\n",
    "\n",
    "colors = itertools.cycle(palette)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "# Products per Country for each city.\n",
    "plots = []\n",
    "product_groups = df.groupby(['cm_name'])\n",
    "for prod_group, prod_row in product_groups:    \n",
    "    plot = figure(x_axis_type=\"datetime\", title=\"{} in {}\".format(prod_group, country), tools='hover')\n",
    "    \n",
    "    city_groups = prod_row.groupby(['mkt_name'])\n",
    "    for (group, row), color in zip(city_groups, colors):\n",
    "        plot.line(datetime(row['date']), row['Diff'], color=color, legend=group)\n",
    "    plot.legend.click_policy = \"hide\"\n",
    "    plot.legend.location = \"top_right\"\n",
    "    hover = plot.select(dict(type=HoverTool))\n",
    "    hover.tooltips = [\n",
    "        (\"Value\", \"$y\"),\n",
    "        ]\n",
    "    \n",
    "    plots.append(plot)\n",
    "\n",
    "# p2 = figure(x_axis_type=\"datetime\", title=\"Bread in Afghanistan\")\n",
    "# p2.line(datetime(df['date']), df['mp_price'], color='#A6CEE3', legend='Bread')\n",
    "\n",
    "# show(gridplot([plots]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "\n",
    "Are there any food prices that are show negative/positive correlation, and is this correlation present throughout the years, or perhaps only in certain period? Can you perhaps detect possible ingredients of a certain other food product?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each product in a graph for each country.\n",
    "\n",
    "country = 'Uganda'\n",
    "y_axis = 'Gradient'\n",
    "\n",
    "df_country = df.loc[df.adm0_name == country]\n",
    "plots = []\n",
    "country_groups = df_country.groupby(['mkt_name'])\n",
    "\n",
    "# allow for interactive hover tool\n",
    "# Import the ColumnDataSource\n",
    "from bokeh.models import ColumnDataSource\n",
    "\n",
    "\n",
    "\n",
    "for country_group, country_row in country_groups:\n",
    "    plot = figure(x_axis_type=\"datetime\", title=\"Products in {}\".format(country_group), tools='hover,pan,wheel_zoom,box_zoom,reset')\n",
    "    product_groups = country_row.groupby(['cm_name'])\n",
    "    for (group, row), color in zip(product_groups, colors):\n",
    "        # create CDS to enable dynamic hovering\n",
    "        row_cds = ColumnDataSource(row)\n",
    "        # set source to CDS\n",
    "        # OK to use Gradient for derivative?\n",
    "        plot.line('date', y_axis, color=color, legend=group, source=row_cds)\n",
    "    plot.legend.click_policy = \"hide\"\n",
    "    plot.legend.location = \"top_right\"\n",
    "    hover = plot.select(dict(type=HoverTool))\n",
    "    # set preffered info for hovertool to show\n",
    "    hover.tooltips = [\n",
    "        # need to fix daytime again now....\n",
    "        (\"date\", \"@date\"),\n",
    "        (\"product\", \"@cm_name\"),\n",
    "        (\"Gradient\", \"@Gradient\")\n",
    "        ]\n",
    "    \n",
    "    plots.append(plot)\n",
    "\n",
    "show(gridplot([plots]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "Do countries in similar regions, also show similar price differences? And if differences occur, can you find a potential explanation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each product in a graph for each country.\n",
    "\n",
    "\n",
    "region_df = pd.read_csv(regional_file_name)\n",
    "region_df.rename(columns={'name': 'adm0_name'}, inplace=True)\n",
    "new_regions = region_df.loc[:, ['adm0_name', 'sub-region']]\n",
    "\n",
    "df_regions = pd.merge(df, new_regions, on='adm0_name', how='left')\n",
    "df = df_regions.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_axis = 'Gradient'\n",
    "\n",
    "\n",
    "plots = []\n",
    "product_groups = df.groupby(['sub-region', 'cm_name', 'date'])[y_axis].mean().reset_index()\n",
    "group = product_groups.groupby('sub-region')\n",
    "\n",
    "for gr1, row1 in group:\n",
    "    plot = figure(x_axis_type=\"datetime\", title=\"Avg Products in {}\".format(gr1), tools='hover,pan,wheel_zoom,box_zoom,reset')\n",
    "    product_groups = row1.groupby(['cm_name'])\n",
    "    for (gr2, row2), color in zip(product_groups, colors):\n",
    "        row2_cds = ColumnDataSource(row2)\n",
    "        plot.line('date', y_axis, color=color, legend=gr2, source=row2_cds)\n",
    "    plot.legend.click_policy = \"hide\"\n",
    "    plot.legend.location = \"top_right\"\n",
    "    hover = plot.select(dict(type=HoverTool))\n",
    "    hover.tooltips = [\n",
    "        (\"Product\", \"@cm_name\"),\n",
    "        (\"Value\", \"@Gradient\"),\n",
    "        ]\n",
    "    \n",
    "    plots.append(plot)\n",
    "show(gridplot([plots]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "Can we see any correlations between other types of data, like: currency fluctuations, weather patterns, and/or refugee movements. Can we perhaps visualize refugee movements from the food price data? Do certain weather conditions influence market prices?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin</th>\n",
       "      <th>frequency</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1</td>\n",
       "      <td>2007-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>18</td>\n",
       "      <td>2016-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>19</td>\n",
       "      <td>2016-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>1</td>\n",
       "      <td>2006-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>1</td>\n",
       "      <td>2011-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Egypt</td>\n",
       "      <td>1</td>\n",
       "      <td>2005-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Egypt</td>\n",
       "      <td>1</td>\n",
       "      <td>2006-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Egypt</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Barbados</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>1</td>\n",
       "      <td>2006-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Bosnia and Herzegovina</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-08-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Bosnia and Herzegovina</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>China</td>\n",
       "      <td>3</td>\n",
       "      <td>2006-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>China</td>\n",
       "      <td>5</td>\n",
       "      <td>2006-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>China</td>\n",
       "      <td>1</td>\n",
       "      <td>2009-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>China</td>\n",
       "      <td>1</td>\n",
       "      <td>2011-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>China</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Democratic Republic of the Congo</td>\n",
       "      <td>5</td>\n",
       "      <td>2012-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Democratic Republic of the Congo</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Democratic Republic of the Congo</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Czech Rep.</td>\n",
       "      <td>4</td>\n",
       "      <td>2007-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Eritrea</td>\n",
       "      <td>5</td>\n",
       "      <td>2014-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Eritrea</td>\n",
       "      <td>7</td>\n",
       "      <td>2014-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Eritrea</td>\n",
       "      <td>6</td>\n",
       "      <td>2014-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Eritrea</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Gambia</td>\n",
       "      <td>2</td>\n",
       "      <td>2012-08-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Gambia</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Palestinian</td>\n",
       "      <td>1</td>\n",
       "      <td>2005-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>4</td>\n",
       "      <td>2004-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1</td>\n",
       "      <td>2004-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>3</td>\n",
       "      <td>2004-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>3</td>\n",
       "      <td>2004-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>4</td>\n",
       "      <td>2004-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>8</td>\n",
       "      <td>2004-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1</td>\n",
       "      <td>2004-08-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>63</td>\n",
       "      <td>2004-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>3</td>\n",
       "      <td>2004-10-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>4</td>\n",
       "      <td>2004-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2</td>\n",
       "      <td>2005-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1</td>\n",
       "      <td>2005-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>8</td>\n",
       "      <td>2005-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2</td>\n",
       "      <td>2005-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>3</td>\n",
       "      <td>2005-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1</td>\n",
       "      <td>2005-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2</td>\n",
       "      <td>2005-08-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>7</td>\n",
       "      <td>2005-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1</td>\n",
       "      <td>2005-10-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2</td>\n",
       "      <td>2005-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1</td>\n",
       "      <td>2006-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2</td>\n",
       "      <td>2006-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1</td>\n",
       "      <td>2006-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1</td>\n",
       "      <td>2006-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>5</td>\n",
       "      <td>2006-08-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>4</td>\n",
       "      <td>2006-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2</td>\n",
       "      <td>2006-10-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>5</td>\n",
       "      <td>2006-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1</td>\n",
       "      <td>2006-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1</td>\n",
       "      <td>2007-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               origin frequency       date\n",
       "0                         Afghanistan         1 2007-11-01\n",
       "1                         Afghanistan         1 2012-09-01\n",
       "2                         Afghanistan        18 2016-06-01\n",
       "3                         Afghanistan        19 2016-07-01\n",
       "4                             Algeria         1 2006-11-01\n",
       "5                             Algeria         1 2011-07-01\n",
       "6                               Egypt         1 2005-04-01\n",
       "7                               Egypt         1 2006-11-01\n",
       "8                               Egypt         1 2010-02-01\n",
       "9                            Barbados         1 2012-11-01\n",
       "10                         Bangladesh         1 2006-02-01\n",
       "11                         Bangladesh         1 2011-01-01\n",
       "12             Bosnia and Herzegovina         1 2010-08-01\n",
       "13             Bosnia and Herzegovina         1 2013-02-01\n",
       "14                              China         3 2006-03-01\n",
       "15                              China         5 2006-05-01\n",
       "16                              China         1 2009-05-01\n",
       "17                              China         1 2011-05-01\n",
       "18                              China         1 2013-01-01\n",
       "19   Democratic Republic of the Congo         5 2012-05-01\n",
       "20   Democratic Republic of the Congo         1 2016-02-01\n",
       "21   Democratic Republic of the Congo         2 2016-04-01\n",
       "22                         Czech Rep.         4 2007-03-01\n",
       "23                            Eritrea         5 2014-05-01\n",
       "24                            Eritrea         7 2014-07-01\n",
       "25                            Eritrea         6 2014-09-01\n",
       "26                            Eritrea         5 2015-06-01\n",
       "27                             Gambia         2 2012-08-01\n",
       "28                             Gambia         1 2013-09-01\n",
       "29                        Palestinian         1 2005-06-01\n",
       "..                                ...       ...        ...\n",
       "170                       Afghanistan         4 2004-02-01\n",
       "171                       Afghanistan         1 2004-03-01\n",
       "172                       Afghanistan         3 2004-04-01\n",
       "173                       Afghanistan         3 2004-05-01\n",
       "174                       Afghanistan         4 2004-06-01\n",
       "175                       Afghanistan         8 2004-07-01\n",
       "176                       Afghanistan         1 2004-08-01\n",
       "177                       Afghanistan        63 2004-09-01\n",
       "178                       Afghanistan         3 2004-10-01\n",
       "179                       Afghanistan         4 2004-11-01\n",
       "180                       Afghanistan         2 2005-01-01\n",
       "181                       Afghanistan         1 2005-02-01\n",
       "182                       Afghanistan         8 2005-03-01\n",
       "183                       Afghanistan         2 2005-04-01\n",
       "184                       Afghanistan         3 2005-05-01\n",
       "185                       Afghanistan         1 2005-07-01\n",
       "186                       Afghanistan         2 2005-08-01\n",
       "187                       Afghanistan         7 2005-09-01\n",
       "188                       Afghanistan         1 2005-10-01\n",
       "189                       Afghanistan         2 2005-11-01\n",
       "190                       Afghanistan         1 2006-02-01\n",
       "191                       Afghanistan         2 2006-04-01\n",
       "192                       Afghanistan         1 2006-05-01\n",
       "193                       Afghanistan         1 2006-07-01\n",
       "194                       Afghanistan         5 2006-08-01\n",
       "195                       Afghanistan         4 2006-09-01\n",
       "196                       Afghanistan         2 2006-10-01\n",
       "197                       Afghanistan         5 2006-11-01\n",
       "198                       Afghanistan         1 2006-12-01\n",
       "199                       Afghanistan         1 2007-01-01\n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# get datasets\n",
    "# https://data.world/unhcr/asylum-applications/workspace/file?filename=asylum_seekers_monthly_2016_12_08_152150.csv\n",
    "asylum_file = 'asylum_seekers_monthly_2016_12_08_152150.csv'\n",
    "df = pd.read_csv(asylum_file, low_memory=False)\n",
    "\n",
    "food_prices_file = 'WFPVAM_FoodPrices_version5_Retail.csv'\n",
    "df_food = pd.read_csv(food_prices_file)\n",
    "\n",
    "\n",
    "####### pre-processing #######################################################################\n",
    "\n",
    "df.columns = ['destination', 'origin', 'year', 'month', 'frequency']\n",
    "# remove abundant rows\n",
    "df.drop(df.index[:2], inplace=True)\n",
    "\n",
    "# map month names to corresponding number to allow for convertion to daytime\n",
    "MONTH_DICT = {'January': 1, 'February': 2, 'March': 3, 'April': 4, 'May': 5, 'June': 6, \n",
    "              'July': 7, 'August': 8, 'September': 9, 'October': 10, 'November': 11,\n",
    "              'December': 12}\n",
    "\n",
    "df['month'] = df['month'].map(MONTH_DICT)\n",
    "\n",
    "# month and year column to single daytime column 'date'\n",
    "df = df.assign(date=pd.to_datetime(df[['year', 'month']].assign(day=1)))\n",
    "# drop now abundant columns month and year\n",
    "df = df.drop('month', axis=1)\n",
    "df = df.drop('year', axis=1)\n",
    "\n",
    "# drop rows with undefined frequency\n",
    "df = df.drop(df[df.frequency == '*'].index)\n",
    "# also drop rows with unknown/various origins\n",
    "df = df.drop(df[df.origin == 'Various/unknown'].index)\n",
    "\n",
    "# NB: we could also drop the destination columns, since it only includes countries\n",
    "# outside of our original dataset. But maybe it will allow for some dynamic hovering later on...\n",
    "# so we'll keep it for now.\n",
    "\n",
    "# see if different names are used for identical counrtries in the two databases:\n",
    "# will end up with a list with countries that don't match; manually see if they should...\n",
    "countries_food = df_food['Iadm0_name'].unique()\n",
    "countries_refugee = df['origin'].unique()\n",
    "\n",
    "possible_mismatches_1 = [country for country in countries_food \n",
    "                       if country not in countries_refugee]\n",
    "\n",
    "possible_mismatches_2 = [country for country in countries_refugee\n",
    "                        if country not in countries_food]\n",
    "\n",
    "definite_mismatches = possible_mismatches_1 + possible_mismatches_2\n",
    "\n",
    "mismatches = definite_mismatches.sort()\n",
    "# print(mismatches)\n",
    "\n",
    "# {'country name in refugee file': 'corresponding country name in food dataset'}\n",
    "MISMATCH_DICT = {'Iran (Islamic Rep. of)': 'Iran  (Islamic Republic of)', 'Dem. Rep. of the Congo': 'Democratic Republic of the Congo',\n",
    "                 'Central African Rep.': 'Central African Republic'}\n",
    "\n",
    "# fix mis-matches\n",
    "for (original, new) in MISMATCH_DICT.items():\n",
    "    mask = df.origin == original\n",
    "    df.loc[mask, 'origin'] = new\n",
    "    \n",
    "# reset index\n",
    "df = df.reset_index(drop=True)\n",
    "df.head()\n",
    "###################################### pre-processing done ###################################\n",
    "\n",
    "\n",
    "# set food_prices dataset to daytime to allow merging with refugee dataset\n",
    "#df_food['date'] = pd.to_datetime(df_food.date, format='%Y-%m')\n",
    "# merge datasets \n",
    "\n",
    "#new_df = pd.merge(df_food, df,  how='left', left_on=['Iadm0_name','date'], right_on = ['origin','date'])\n",
    "# drop now abundantan origin row (equals Iadm0_name)\n",
    "#new_df[:50]\n",
    "\n",
    "# drop destination column\n",
    "df = df.drop('destination', axis=1)\n",
    "\n",
    "\n",
    "df[:200]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
